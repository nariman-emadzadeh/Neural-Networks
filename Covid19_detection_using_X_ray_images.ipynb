{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vWxzGS08AcVK"
   },
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CDBYcQCeAUAp"
   },
   "outputs": [],
   "source": [
    "# Sequetial is used to build different layers in the neural network\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Conv2d helps the model to learn specific features and sharpening detections in the image\n",
    "# Maxpooling reduces the size of the data without loosing important features in the image\n",
    "# Dropout prevents overfitting. It randomly looses / drop connections between neurons\n",
    "# Flatten layer transfroms a 2D matrix of features to a vector that can fit in the fully connected layer\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
    "\n",
    "# Adam (Adaptive Momentum) optimizer \n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# ImageDataGenerator is used for image augmentation to increase the sample size. Making slight modifications such as rotation\n",
    "# so the model can learn more effectively from many variations\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hMRiBWpYAiOQ"
   },
   "source": [
    "# TASK 2 : Clone & Explore dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lY1sIb7GI_m5",
    "outputId": "2f944279-1d96-44c4-c0e5-acf9803832c9"
   },
   "outputs": [],
   "source": [
    "#clone the dataset from the github repository\n",
    "! git clone https://github.com/education454/datasets.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qv3ykJOtAn7k"
   },
   "outputs": [],
   "source": [
    "#set the path to the main dir\n",
    "import os\n",
    "main_dir = \"/content/datasets/Data\"\n",
    "\n",
    "#set the path to the train dir\n",
    "train_dir = os.path.join(main_dir,\"train\")\n",
    "\n",
    "#set the path to the test dir\n",
    "test_dir = os.path.join(main_dir, \"test\")\n",
    "\n",
    "#directory with the training covid images\n",
    "train_covid_dir = os.path.join(train_dir, \"COVID19\")\n",
    "\n",
    "#directory with the training normal images\n",
    "train_normal_dir = os.path.join(train_dir, \"NORMAL\")\n",
    "#directory with the testing covid images\n",
    "test_covid_dir = os.path.join(test_dir, \"COVID19\")\n",
    "#directory with the testing normal images\n",
    "test_normal_dir = os.path.join(test_dir, \"NORMAL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s_QyIqfcBUwv",
    "outputId": "7fbfed8c-a9f6-42db-9430-c4c5bebca768"
   },
   "outputs": [],
   "source": [
    "#print the filenames\n",
    "# Takes in each directory and converts it to a list\n",
    "train_covid_names = os.listdir(train_covid_dir)\n",
    "print(\"The type for the train_covid_names is: \", type(train_covid_names))\n",
    "print(train_covid_names[:10])\n",
    "\n",
    "\n",
    "train_normal_names = os.listdir(train_normal_dir)\n",
    "print(train_normal_names[:10])\n",
    "\n",
    "test_covid_names = os.listdir(test_covid_dir)\n",
    "print(test_covid_names[:10])\n",
    "\n",
    "test_normal_names = os.listdir(test_normal_dir)\n",
    "print(test_normal_names[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8_PDJQWuBU8U",
    "outputId": "af9bbfc8-9505-4c87-b321-bb2a450d8aee"
   },
   "outputs": [],
   "source": [
    "#print the total no of images present in each dir\n",
    "print(\"Total COVID19 images in the training set: \", len(train_covid_names))\n",
    "print(\"Total NORMAL images in the training set: \", len(train_normal_names))\n",
    "print(\"Total COVID19 images in the testing set: \", len(test_covid_names))\n",
    "print(\"Total Normal images in the testing set: \", len(test_normal_names))\n",
    "print(\"Total images present in the training set :\", len(train_covid_names + train_normal_names))\n",
    "print(\"Total images present in the testing set :\", len(test_covid_names + test_normal_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NMPZ9t8UBogq"
   },
   "source": [
    "# TASK 3 : Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 751
    },
    "id": "vryI0-PKBtLF",
    "outputId": "39bff4d6-4337-4602-96f1-1643abe270f4"
   },
   "outputs": [],
   "source": [
    "# plot a grid of 16 images (8 images of Covid19 and 8 images of Normal)\n",
    "import matplotlib.image as mpimg\n",
    "#set the number of columns and rows\n",
    "rows = 4\n",
    "cols = 4\n",
    "#set the figure size - get the current figure (gcf)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(12,12)\n",
    "#get the filenames from the covid & normal dir of the train dataset\n",
    "covid_pic = [os.path.join(train_covid_dir, filename) for filename in train_covid_names [0:8]]\n",
    "normal_pic = [os.path.join(train_normal_dir, filename) for filename in train_normal_names[0:8]]\n",
    "#print the list\n",
    "print(covid_pic)\n",
    "print(normal_pic)\n",
    "#merge the covid and normal list\n",
    "merged_list = covid_pic + normal_pic\n",
    "for i , img_path in enumerate(merged_list):\n",
    "  # it will transform the img directory to a list by splitting them based on the \"/\" pattern\n",
    "  # to get only the name part, we are taking the last element from the list by using [-1]\n",
    "  data = img_path.split('/')[-1]\n",
    "  sp = plt.subplot(rows, cols, i + 1)\n",
    "  sp.axis('off')\n",
    "  img = mpimg.imread(img_path)\n",
    "  sp.set_title(data,fontsize=10)\n",
    "  plt.imshow(img, cmap = 'gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UWiQARLdCB9J"
   },
   "source": [
    "# TASK 4 : Data Preprocessing & Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZU7C28QWB_il",
    "outputId": "035ea19d-74a7-4d32-cae6-0dede0c6194d"
   },
   "outputs": [],
   "source": [
    "# generate training,testing and validation batches \n",
    "# rescale normalizes the pixel values\n",
    "# validation_split randomly places the allocated percentage of the data in the validation set and the remaining in the training set\n",
    "# zoom_range randomly zooms in parts of the images\n",
    "# horizontal_flip randomly flips inputs horizontally\n",
    "dgen_train = ImageDataGenerator(rescale=1./255,\n",
    "                                validation_split = 0.2,\n",
    "                                zoom_range = 0.2,\n",
    "                                horizontal_flip = True)\n",
    "dgen_validation = ImageDataGenerator(rescale = 1./255)\n",
    "dgen_test = ImageDataGenerator(rescale= 1./255)\n",
    "\n",
    "# flow_from_directory loads the images from the directory\n",
    "# target_size rescales our image to 150 by 150 pixels\n",
    "# subset specifies whether the training or validation subset is passed\n",
    "# batch_size specifies how many images pass through the model at once\n",
    "# class_mode if only two outputs then its binary otherwise categorical\n",
    "train_generator = dgen_train.flow_from_directory(train_dir,\n",
    "                                                 target_size = (150, 150),\n",
    "                                                 subset = 'training',\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')\n",
    "\n",
    "validation_generator = dgen_train.flow_from_directory(train_dir,\n",
    "                                                           target_size = (150, 150),\n",
    "                                                           subset = 'validation',\n",
    "                                                           batch_size = 32,\n",
    "                                                           class_mode = 'binary')\n",
    "\n",
    "test_generator = dgen_test.flow_from_directory(test_dir,\n",
    "                                               target_size = (150, 150),\n",
    "                                               batch_size = 32,\n",
    "                                               class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SIdVxgoLGb0K",
    "outputId": "0fa5ec51-3178-4599-8f6c-fd04b3197f2a"
   },
   "outputs": [],
   "source": [
    "#get the class indices\n",
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gMe4b6_YGdlt",
    "outputId": "59db2df5-da54-479d-9bd5-c4acffd21b9f"
   },
   "outputs": [],
   "source": [
    "#get the image shape\n",
    "train_generator.image_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ELcsfIibGoK3"
   },
   "source": [
    "# TASK 5 : Build Convolutional Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_-pwXOyuGxIq",
    "outputId": "010be9ea-14a0-4fa4-98af-d8fdfae3cbf3"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# add the convolutional layer\n",
    "# filters, size of filters,padding,activation_function,input_shape\n",
    "# First we take 32 features of the image using 5 by 5 filters\n",
    "# padding same means the output size is the same as the input size. This requires the filter window to slip outside the input map, hence the need to pad \n",
    "# Since this is the first layer, we need to specify the input_shape as the image shape. 3 represents the RGB channels\n",
    "model.add(Conv2D(32,(5,5), padding = 'SAME', activation = 'relu', input_shape = (150, 150, 3)))\n",
    "# pooling layer- to reduce the dimmensionality to reduce the training time\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "# place a dropout layer\n",
    "model.add(Dropout(0.5))\n",
    "# add another convolutional layer\n",
    "model.add(Conv2D(64,(5,5), padding = 'SAME', activation = 'relu'))\n",
    "# pooling layer\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "# place a dropout layer\n",
    "model.add(Dropout(0.5))\n",
    "# Flatten layer - convert the image from 2D to 1D\n",
    "model.add(Flatten())\n",
    "# add a dense layer : amount of nodes, activation\n",
    "model.add(Dense(256, activation = 'relu'))\n",
    "# place a dropout layer\n",
    "# 0.5 drop out rate is recommended, half input nodes will be dropped at each update\n",
    "model.add(Dropout(0.5))\n",
    "# Since we are dealing with a binary classification problem, we are adding 1 followed by sigmoid\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hgCag-_HHG2N"
   },
   "source": [
    "# TASK 6 : Compile & Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1iVcxB1ZHNDV"
   },
   "outputs": [],
   "source": [
    "#compile the model\n",
    "# using the adam optimizer with a learning rate of 0.001; loss binary cross entropy since we have 2 categories\n",
    "model.compile(Adam(lr = 0.001), loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OWtZjCFlHPQs",
    "outputId": "0a901e53-f8d8-4ac7-9cd9-ddd40eb8dd8b"
   },
   "outputs": [],
   "source": [
    "#train the model\n",
    "history = model.fit(train_generator,\n",
    "                    epochs = 30,\n",
    "                    validation_data = validation_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z95l8IC5HRoG"
   },
   "source": [
    "# TASK 7 : Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 181
    },
    "id": "M0d8G-BEHXXs",
    "outputId": "ee6a23e2-407b-459a-ebeb-fa8f4664ecfe"
   },
   "outputs": [],
   "source": [
    "#get the keys of history object\n",
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EVtqI0QuHbZR"
   },
   "outputs": [],
   "source": [
    "#plot graph between training and validation loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.legend(['Training', 'Validation'])\n",
    "plt.title('Training and Validation Losses')\n",
    "plt.xlabel('epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CEIibDQOHgfT"
   },
   "outputs": [],
   "source": [
    "#plot graph between training and validation accuarcy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.legend(['Training', 'Validation'])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U9Zm__wJHm3v"
   },
   "outputs": [],
   "source": [
    "# get the test acuarcy and loss\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print('Test Loss: {} Test Accuracy: {}'.format(test_loss,test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-AZjx1Q2HseZ"
   },
   "source": [
    "# TASK 8 : Prediction On New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b5qflf3jH3o_"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "from keras.preprocessing import image\n",
    "uploaded = files.upload()\n",
    "for filename in uploaded.keys():\n",
    "  img_path = '/content/'+filename\n",
    "  img = image.load_img(img_path, target_size = (150,150))\n",
    "  images = image.img_to_array(img)\n",
    "  images = np.expand_dims(images, axis = 0)\n",
    "  prediction = model.predict(images)\n",
    "  print(filename)\n",
    "\n",
    "  if prediction ==0:\n",
    "    print('COVID19 Detected')\n",
    "  else: \n",
    "    print(\"The X-ray report is normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Covid19_detection_using_X_ray_images.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
